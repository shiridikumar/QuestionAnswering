{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2lwaQV20OWs",
        "outputId": "de03c97d-908f-4878-e835-7fd275dbcc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import io\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.append('/content/drive/My Drive/')\n",
        "\n",
        "!cp -r \"/content/drive/My Drive/BERT/Data/train-v2.0.json\" '/content/'\n",
        "!cp -r \"/content/drive/My Drive/BERT/Data/dev-v2.0.json\" '/content/'\n",
        "!cp -r \"/content/drive/My Drive/BERT/Data/train_data.pkl\" '/content/'\n",
        "!cp -r \"/content/drive/My Drive/BERT/Data/val_data.pkl\" '/content/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RfbxIpS_0OWu"
      },
      "outputs": [],
      "source": [
        "collab = 1\n",
        "if collab == 1:\n",
        "    train_path = '/content/train-v2.0.json'\n",
        "    dev_path = '/content/dev-v2.0.json'\n",
        "else:\n",
        "    train_path = '../Data/train-v2.0.json'\n",
        "    dev_path = '../Data/dev-v2.0.json'\n",
        "\n",
        "with open(train_path) as f:\n",
        "    raw_train_data = json.load(f)\n",
        "\n",
        "with open(dev_path) as f:\n",
        "    raw_dev_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dGcXJhp20OWv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, BertForQuestionAnswering\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "slowTokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "save_path = '../Data/bert_base_uncased/'\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "slowTokenizer.save_pretrained(save_path)\n",
        "\n",
        "# loading the tokenizer from the saved file\n",
        "tokenizer = BertWordPieceTokenizer('../Data/bert_base_uncased/vocab.txt', lowercase=True)\n",
        "maxLength = 384"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Us7AGGJ50OWw"
      },
      "outputs": [],
      "source": [
        "class SQUADExample:\n",
        "    \"\"\"\n",
        "    A single training/test example for the Squad dataset, as loaded from disk.\n",
        "    \"\"\"\n",
        "    def __init__(self, context, question, basic_answer, more_answers, startingIdx):\n",
        "        self.context = context\n",
        "        self.question = question\n",
        "        self.basic_answer = basic_answer\n",
        "        self.more_answers = more_answers\n",
        "        self.startingIdx = startingIdx\n",
        "        self.endingIdx = None\n",
        "        self.attention_mask = None\n",
        "        self.input_ids = None\n",
        "        self.tokenTypeIds = None\n",
        "        self.offSets = None\n",
        "        self.validExample = True\n",
        "        self.startIdxtoken = startingIdx\n",
        "        self.endIndextoken = None\n",
        "\n",
        "    def preProcessing(self):\n",
        "        newContext = str(self.context).lower().split()\n",
        "        self.context = ' '.join(newContext)\n",
        "        newQuestion = str(self.question).lower().split()\n",
        "        self.question = ' '.join(newQuestion)\n",
        "        contextTokens = tokenizer.encode(self.context)\n",
        "        if self.basic_answer is not None :\n",
        "            # if we have answer\n",
        "            self.basic_answer = ' '.join(str(self.basic_answer).lower().split())\n",
        "            self.endingIdx = self.startingIdx + len(self.basic_answer)\n",
        "            if self.endingIdx >= len(self.context):\n",
        "                self.validExample = False\n",
        "                return\n",
        "\n",
        "            # iterate from start to end to find the characters of context\n",
        "            isPartOfAnswer = [0] * len(self.context)\n",
        "            for idx in range(self.startingIdx, self.endingIdx):\n",
        "                isPartOfAnswer[idx] = 1\n",
        "\n",
        "            answerIdToken = []\n",
        "            for idx, (start, end) in enumerate(contextTokens.offsets):\n",
        "                if sum(isPartOfAnswer[start:end]) > 0:\n",
        "                    answerIdToken.append(idx)\n",
        "            # data to predict the start and end index of the answer\n",
        "            if len(answerIdToken) == 0:\n",
        "                self.validExample = False\n",
        "                return\n",
        "            self.startIdxtoken = answerIdToken[0]\n",
        "            self.endIndextoken = answerIdToken[-1]\n",
        "\n",
        "        self.offSets = contextTokens.offsets\n",
        "        questionTokenizer = tokenizer.encode(self.question)\n",
        "        self.input_ids = contextTokens.ids + questionTokenizer.ids[1:]\n",
        "        self.attention_mask = [1] * len(self.input_ids)\n",
        "        self.tokenTypeIds = [0] * len(contextTokens.ids) + [1] * len(questionTokenizer.ids[1:])\n",
        "\n",
        "        # padding fixing\n",
        "        paddingLength = maxLength - len(self.input_ids)\n",
        "        if paddingLength > 0:\n",
        "            self.input_ids = self.input_ids + ([0] * paddingLength)\n",
        "            self.attention_mask = self.attention_mask + ([0] * paddingLength)\n",
        "            self.tokenTypeIds = self.tokenTypeIds + ([0] * paddingLength)\n",
        "        elif paddingLength < 0:\n",
        "            self.validExample = False\n",
        "            return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VI7llTGj0OWy"
      },
      "outputs": [],
      "source": [
        "def createSquadExamples(raw_data):\n",
        "    squadExamples = []\n",
        "    for item in raw_data['data']:\n",
        "        for para in item['paragraphs']:\n",
        "            context = para['context']\n",
        "            for qa in para['qas']:\n",
        "                question = qa['question']\n",
        "                basic_answer = None\n",
        "                more_answers = []\n",
        "                startingIdx = None\n",
        "                if qa['is_impossible']:\n",
        "                    basic_answer = None\n",
        "                else:\n",
        "                    basic_answer = qa['answers'][0]['text']\n",
        "                    startingIdx = qa['answers'][0]['answer_start']\n",
        "                squadEg = SQUADExample(context, question, basic_answer, more_answers, startingIdx)\n",
        "                squadEg.preProcessing()\n",
        "                squadExamples.append(squadEg)\n",
        "    return squadExamples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P9qTYYQY0OWz"
      },
      "outputs": [],
      "source": [
        "def createInputsTargets(squad_example):\n",
        "    datasetDict = {}\n",
        "    for item in squad_example:\n",
        "        if item.validExample:\n",
        "            for key in ['input_ids', 'attention_mask', 'tokenTypeIds', 'startIdxtoken', 'endIndextoken']:\n",
        "                if key not in datasetDict:\n",
        "                    datasetDict[key] = []\n",
        "                datasetDict[key].append(item.__dict__[key])\n",
        "\n",
        "    for key in datasetDict:\n",
        "        datasetDict[key] = np.array(datasetDict[key], dtype=np.float16)\n",
        "\n",
        "    x = [datasetDict['input_ids'], datasetDict['attention_mask'], datasetDict['tokenTypeIds']]\n",
        "    y = [datasetDict['startIdxtoken'], datasetDict['endIndextoken']]\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r9n46pmX0OWz"
      },
      "outputs": [],
      "source": [
        "train_data = createSquadExamples(raw_train_data)\n",
        "val_data = createSquadExamples(raw_dev_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dpGTaKZP0OWz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pickle\n",
        "with open('../Data/train_data.pkl', 'wb') as f:\n",
        "    pickle.dump(train_data, f)\n",
        "\n",
        "with open('../Data/val_data.pkl', 'wb') as f:\n",
        "    pickle.dump(val_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JaKfLpJ50OW0"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "import pickle\n",
        "with open('../content/train_data.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "with open('../content/val_data.pkl', 'rb') as f:\n",
        "    val_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "waJybQEO0OW0"
      },
      "outputs": [],
      "source": [
        "# store the data in csv format\n",
        "train_df = pd.DataFrame([vars(f) for f in train_data])\n",
        "val_df = pd.DataFrame([vars(f) for f in val_data])\n",
        "\n",
        "# train_df.to_csv('../Data/train.csv', index=False)\n",
        "# val_df.to_csv('../Data/val.csv', index=False)\n",
        "\n",
        "# # load the data from csv format\n",
        "# train_df = pd.read_csv('../Data/train.csv')\n",
        "# val_df = pd.read_csv('../Data/val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "mQ063jOD0OW0",
        "outputId": "66e2d348-a0a4-4c50-96f6-0dac00927247"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-117d0083-7c00-48f4-aa78-65f4196735e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>basic_answer</th>\n",
              "      <th>startIdxtoken</th>\n",
              "      <th>endIndextoken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63671</th>\n",
              "      <td>the yale provost's office has launched several...</td>\n",
              "      <td>who was appointed acting president of yale in ...</td>\n",
              "      <td>hanna holborn gray</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40659</th>\n",
              "      <td>the ammunition and shells fired by these weapo...</td>\n",
              "      <td>smaller .50 caliber and 8 millimeter guns have...</td>\n",
              "      <td>smallest mounts</td>\n",
              "      <td>109.0</td>\n",
              "      <td>110.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89683</th>\n",
              "      <td>the alaska railroad was one of the last railro...</td>\n",
              "      <td>the arr was one of the last railroads in the u...</td>\n",
              "      <td>cabooses</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73747</th>\n",
              "      <td>the knights of columbus, the world's largest c...</td>\n",
              "      <td>in modern day snet operates as what in new haven?</td>\n",
              "      <td>subsidiary of at&amp;t</td>\n",
              "      <td>315.0</td>\n",
              "      <td>319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85431</th>\n",
              "      <td>with this contribution of von neumann, the axi...</td>\n",
              "      <td>what was the central theme of godel's announce...</td>\n",
              "      <td>they cannot prove every truth which is express...</td>\n",
              "      <td>85.0</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75669</th>\n",
              "      <td>in january 1871, george jackson mivart's on th...</td>\n",
              "      <td>what was chapter vii entitled?</td>\n",
              "      <td>miscellaneous objections</td>\n",
              "      <td>87.0</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109559</th>\n",
              "      <td>the final stage of database design is to make ...</td>\n",
              "      <td>what decisions are optional in the last stage ...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62494</th>\n",
              "      <td>data compression can be viewed as a special ca...</td>\n",
              "      <td>what can be classified as data differencing wi...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10711</th>\n",
              "      <td>le: life expectancy at birth mys: mean years o...</td>\n",
              "      <td>what does mis stand for?</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93368</th>\n",
              "      <td>classical statistical mechanics requires the e...</td>\n",
              "      <td>what is not required to exist in modern statis...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-117d0083-7c00-48f4-aa78-65f4196735e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-117d0083-7c00-48f4-aa78-65f4196735e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-117d0083-7c00-48f4-aa78-65f4196735e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-95479da6-7f7f-460d-957b-484b40404265\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95479da6-7f7f-460d-957b-484b40404265')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-95479da6-7f7f-460d-957b-484b40404265 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  context  \\\n",
              "63671   the yale provost's office has launched several...   \n",
              "40659   the ammunition and shells fired by these weapo...   \n",
              "89683   the alaska railroad was one of the last railro...   \n",
              "73747   the knights of columbus, the world's largest c...   \n",
              "85431   with this contribution of von neumann, the axi...   \n",
              "75669   in january 1871, george jackson mivart's on th...   \n",
              "109559  the final stage of database design is to make ...   \n",
              "62494   data compression can be viewed as a special ca...   \n",
              "10711   le: life expectancy at birth mys: mean years o...   \n",
              "93368   classical statistical mechanics requires the e...   \n",
              "\n",
              "                                                 question  \\\n",
              "63671   who was appointed acting president of yale in ...   \n",
              "40659   smaller .50 caliber and 8 millimeter guns have...   \n",
              "89683   the arr was one of the last railroads in the u...   \n",
              "73747   in modern day snet operates as what in new haven?   \n",
              "85431   what was the central theme of godel's announce...   \n",
              "75669                      what was chapter vii entitled?   \n",
              "109559  what decisions are optional in the last stage ...   \n",
              "62494   what can be classified as data differencing wi...   \n",
              "10711                            what does mis stand for?   \n",
              "93368   what is not required to exist in modern statis...   \n",
              "\n",
              "                                             basic_answer  startIdxtoken  \\\n",
              "63671                                  hanna holborn gray           20.0   \n",
              "40659                                     smallest mounts          109.0   \n",
              "89683                                            cabooses           15.0   \n",
              "73747                                  subsidiary of at&t          315.0   \n",
              "85431   they cannot prove every truth which is express...           85.0   \n",
              "75669                            miscellaneous objections           87.0   \n",
              "109559                                               None            NaN   \n",
              "62494                                                None            NaN   \n",
              "10711                                                None            NaN   \n",
              "93368                                                None            NaN   \n",
              "\n",
              "        endIndextoken  \n",
              "63671            24.0  \n",
              "40659           110.0  \n",
              "89683            17.0  \n",
              "73747           319.0  \n",
              "85431            96.0  \n",
              "75669            88.0  \n",
              "109559            NaN  \n",
              "62494             NaN  \n",
              "10711             NaN  \n",
              "93368             NaN  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print 10 random rows from the training data\n",
        "train_df[['context', 'question', 'basic_answer', 'startIdxtoken', 'endIndextoken']].sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fyozl1f20OW1"
      },
      "outputs": [],
      "source": [
        "X_train , y_train = createInputsTargets(train_data)\n",
        "X_val , y_val = createInputsTargets(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zGYQVieG0OW1"
      },
      "outputs": [],
      "source": [
        "DOC_STRIDE = 64\n",
        "MAX_SEQ_LENGTH = 128\n",
        "MAX_QUERY_LENGTH = 32\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scu1k_Co0OW1",
        "outputId": "7c3be876-f9b2-4c71-fcb0-fb29e04789a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "trainData = TensorDataset(torch.tensor(X_train[0], dtype=torch.int64),\n",
        "                           torch.tensor(X_train[1], dtype=torch.float),\n",
        "                           torch.tensor(X_train[2], dtype=torch.int64),\n",
        "                           torch.tensor(y_train[0], dtype=torch.int64),\n",
        "                           torch.tensor(y_train[1], dtype=torch.int64))\n",
        "\n",
        "train_sampler = RandomSampler(trainData)\n",
        "train_dataloader = DataLoader(\n",
        "    trainData, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if train_on_gpu:\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(\"Training on \" + str(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "STDol2Ih0OW1"
      },
      "outputs": [],
      "source": [
        "validData = TensorDataset(torch.tensor(X_val[0], dtype=torch.int64),\n",
        "                            torch.tensor(X_val[1], dtype=torch.float),\n",
        "                            torch.tensor(X_val[2], dtype=torch.int64),\n",
        "                            torch.tensor(y_val[0], dtype=torch.int64),\n",
        "                            torch.tensor(y_val[1], dtype=torch.int64))\n",
        "valid_sampler = SequentialSampler(validData)\n",
        "valid_dataloader = DataLoader(\n",
        "    validData, sampler=valid_sampler, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wMmBtnh0OW1",
        "outputId": "32f8d8e1-bfa9-4858-9f87-b7a5adf84490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  101, 20768, 21024,  ...,     0,     0,     0],\n",
            "        [  101, 20768, 21024,  ...,     0,     0,     0],\n",
            "        [  101, 20768, 21024,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  1996,  2744,  ...,     0,     0,     0],\n",
            "        [  101,  1996,  2744,  ...,     0,     0,     0],\n",
            "        [  101,  1996,  2744,  ...,     0,     0,     0]])\n"
          ]
        }
      ],
      "source": [
        "print(train_dataloader.dataset.tensors[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oibWvjhE0OW1",
        "outputId": "71d4bd40-c06b-4291-dcc2-e4a36534d1ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
        "param_optimizer = list(model.named_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mXgIHZtj0OW2"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    lr=1e-5, betas=(0.9, 0.98), eps=1e-9, params=optimizer_grouped_parameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YpP54JrW0OW2"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def normalizeText(text):\n",
        "    if text is None or len(text)==0:\n",
        "      return \"\"\n",
        "    text = text.lower()\n",
        "    text = ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE) # remove a, an, the\n",
        "    text = re.sub(regex, ' ', text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hL3WFANS0OW2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm, trange\n",
        "def train(model, train_dataloader, val_data, validation_dataloader, optimizer, epochs=2, max_grad_norm=1.0):\n",
        "    model.train()\n",
        "    for _ in trange(epochs, desc='Epoch'):\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'token_type_ids': batch[2], 'start_positions': batch[3], 'end_positions': batch[4]}\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_steps += 1\n",
        "            torch.nn.utils.clip_grad_norm_( parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            model.zero_grad()\n",
        "            if(step % 100 == 0):\n",
        "              print(\"Batch loss : {}\".format(tr_loss/nb_tr_steps))\n",
        "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "        validate(model, val_data, validation_dataloader)\n",
        "\n",
        "    print(\"Training complete\")\n",
        "\n",
        "def validate(model, val_data, validation_dataloader):\n",
        "    model.eval()\n",
        "    currentQuery = 0\n",
        "    correctAns = 0\n",
        "    validExamples = [x for x in val_data if x.validExample]\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, segment_ids, start_positions, end_positions = batch\n",
        "        with torch.no_grad():\n",
        "            start_scores, end_scores = model(input_ids, token_type_ids=segment_ids,\n",
        "                                             attention_mask=input_mask,return_dict=False)\n",
        "\n",
        "            pred_start, pred_end = start_scores.detach().cpu().numpy(), end_scores.detach().cpu().numpy()\n",
        "\n",
        "        for idx, (start,end) in enumerate(zip(pred_start,pred_end)):\n",
        "            squadEg = validExamples[currentQuery]\n",
        "            currentQuery +=1\n",
        "            offsets = squadEg.offSets\n",
        "            startIdx = np.argmax(start)\n",
        "            endIdx = np.argmax(end)\n",
        "            if startIdx >= len(offsets):\n",
        "                continue\n",
        "            predCharStart = offsets[startIdx][0]\n",
        "            if endIdx < len(offsets):\n",
        "                predCharEnd = offsets[endIdx][1]\n",
        "                predAnswer = squadEg.context[predCharStart:predCharEnd]\n",
        "            else:\n",
        "                predAnswer = squadEg.context[predCharStart:]\n",
        "            if(predAnswer==None):\n",
        "              continue\n",
        "            normalizedPredAnswer = normalizeText(predAnswer)\n",
        "            normalizedTrueAnswer = [normalizeText(x)\n",
        "                                    for x in squadEg.more_answers]\n",
        "            normalizedTrueAnswer.append(normalizeText(squadEg.basic_answer))\n",
        "            if normalizedPredAnswer in normalizedTrueAnswer:\n",
        "                correctAns += 1\n",
        "            if(currentQuery + idx) % 50 == 0:\n",
        "              print(\"Validated {}/{} examples\".format(currentQuery+idx+1, len(validExamples)))\n",
        "    acc = correctAns / len(validExamples)\n",
        "    print(\"Validation Accuracy: {}\".format(acc))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELK80Dy50OW3",
        "outputId": "03958a5e-cca9-4a15-f2fd-59205074eea5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch loss : 6.155097961425781\n",
            "Batch loss : 4.280938927489932\n",
            "Batch loss : 3.805304542702822\n",
            "Batch loss : 3.523900489870496\n",
            "Batch loss : 3.34717895384144\n",
            "Batch loss : 3.2149320372088463\n",
            "Batch loss : 3.127440221496112\n",
            "Batch loss : 3.0497878485501406\n",
            "Batch loss : 2.9870957743362543\n",
            "Batch loss : 2.9295461486103003\n",
            "Batch loss : 2.884565957538136\n",
            "Batch loss : 2.8385461699843515\n",
            "Batch loss : 2.7945155470099277\n",
            "Batch loss : 2.7671483360190834\n",
            "Batch loss : 2.7400712230050672\n",
            "Batch loss : 2.7100623318705854\n",
            "Batch loss : 2.6832910738908673\n",
            "Batch loss : 2.6563685961431225\n",
            "Batch loss : 2.6343041676272954\n",
            "Batch loss : 2.6135999516773576\n",
            "Batch loss : 2.5959379107638756\n",
            "Batch loss : 2.5757736853904123\n",
            "Batch loss : 2.5580772478328084\n",
            "Batch loss : 2.542476883404983\n",
            "Batch loss : 2.5241931669417146\n",
            "Batch loss : 2.5081157502723856\n",
            "Batch loss : 2.4937798252292707\n",
            "Batch loss : 2.481288230096972\n",
            "Batch loss : 2.4660065784832272\n",
            "Batch loss : 2.4537941356725996\n",
            "Batch loss : 2.4396893338178325\n",
            "Batch loss : 2.4276732475440066\n",
            "Batch loss : 2.412613065456532\n",
            "Batch loss : 2.397910351249096\n",
            "Batch loss : 2.3869303092294776\n",
            "Batch loss : 2.3748104826990653\n",
            "Batch loss : 2.362013389868261\n",
            "Batch loss : 2.3484634177261543\n",
            "Batch loss : 2.3379439752342135\n",
            "Batch loss : 2.3273073224739\n",
            "Batch loss : 2.3165912820797687\n",
            "Batch loss : 2.307603547890516\n",
            "Batch loss : 2.2975021468914854\n",
            "Batch loss : 2.2876144562923915\n",
            "Batch loss : 2.279553061817159\n",
            "Batch loss : 2.27089602067666\n",
            "Batch loss : 2.261082210156794\n",
            "Batch loss : 2.253726772426722\n",
            "Batch loss : 2.2456091409349312\n",
            "Batch loss : 2.238167842208938\n",
            "Batch loss : 2.2306356746252716\n",
            "Batch loss : 2.2234909908721505\n",
            "Batch loss : 2.2137881478560106\n",
            "Batch loss : 2.207216754114374\n",
            "Batch loss : 2.199823460232834\n",
            "Batch loss : 2.1930188945349163\n",
            "Batch loss : 2.186477235184676\n",
            "Batch loss : 2.1795266730871936\n",
            "Batch loss : 2.174296760257\n",
            "Batch loss : 2.1676807423867\n",
            "Batch loss : 2.1613573167765465\n",
            "Batch loss : 2.154922590150616\n",
            "Batch loss : 2.148655712931334\n",
            "Batch loss : 2.141398153434082\n",
            "Batch loss : 2.1352434317184006\n",
            "Batch loss : 2.128560060336945\n",
            "Batch loss : 2.122931045016598\n",
            "Batch loss : 2.11680953220865\n",
            "Batch loss : 2.1110922140402755\n",
            "Batch loss : 2.1045668464245235\n",
            "Batch loss : 2.098615002868823\n",
            "Batch loss : 2.0932040188601615\n",
            "Batch loss : 2.0872637882959078\n",
            "Batch loss : 2.0820388546987294\n",
            "Batch loss : 2.0777719409107243\n",
            "Batch loss : 2.0726819249204502\n",
            "Batch loss : 2.0683110234706343\n",
            "Batch loss : 2.0634989470665275\n",
            "Batch loss : 2.0586780824045112\n",
            "Batch loss : 2.0541171353612575\n",
            "Batch loss : 2.0502463271507336\n",
            "Train loss: 2.049263019727567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 1/1 [2:37:22<00:00, 9442.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6898281786941581\n",
            "Training complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, train_dataloader, val_data, valid_dataloader, optimizer, epochs=1, max_grad_norm=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RI9BbFh0wRB_"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('/content/drive/My Drive/BERT/model')\n",
        "# tokenizer.save_pretrained('/content/drive/My Drive/BERT/tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCnhk8nQ0OW3",
        "outputId": "3e47f2bd-d5d5-4232-bf1b-723d371ae853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: when did tesla becοme a vegetarian?\n",
            "A: his later years\n",
            "----------------------------------------\n",
            "\n",
            "Q: when did tesla move to united states ?\n",
            "A: 1884\n",
            "----------------------------------------\n",
            "\n",
            "Q: what year did tesla die?\n",
            "A: 1884, he moved to united states. in 1887, tesla developed an induction motor that ran on alternating current (ac), a power system format that was rapidly expanding in europe and the united states because of its advantages in long-distance, high-voltage transmission. tesla became a vegetarian in his later years, living on only milk, bread, honey, and vegetable juices. on 7 january 1943\n",
            "----------------------------------------\n",
            "\n",
            "Q: who edited the book my inventions: the autobiography of nikola tesla?\n",
            "A: ben johnston\n",
            "----------------------------------------\n",
            "\n",
            "Q: in what age did tesla died?\n",
            "A: 86\n",
            "----------------------------------------\n",
            "\n",
            "Q: who developed an induction motor?\n",
            "A: tesla\n",
            "----------------------------------------\n",
            "\n",
            "Q: where tesla was born?\n",
            "A: austrian empire\n",
            "----------------------------------------\n",
            "\n",
            "Q: what did tesla study?\n",
            "A: engineering and physics\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # ============================================ TESTING ==========================================================\n",
        "data = {\"data\":\n",
        "        [\n",
        "            {\"title\": \"Tesla's Biography\",\n",
        "             \"paragraphs\": [\n",
        "                 {\n",
        "                     \"context\": \"Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, \"\n",
        "                     \"and futurist best known for his contributions to the design of the modern alternating \"\n",
        "                     \"current (AC) electricity supply system. Born and raised in the Austrian Empire,Tesla \"\n",
        "                     \"studied engineering and physics in the 1870s without receiving a degree. In 1884, he \"\n",
        "                     \"moved to United States. In 1887, Tesla developed an induction motor that ran on alternating \"\n",
        "                     \"current (AC), a power system format that was rapidly expanding in Europe and the United \"\n",
        "                     \"States because of its advantages in long-distance, high-voltage transmission. Tesla became \"\n",
        "                     \"a vegetarian in his later years, living on only milk, bread, honey, and vegetable juices. \"\n",
        "                     \"On 7 January 1943, at the age of 86, Tesla died alone in Room 3327 of the Hotel New Yorker. \"\n",
        "                     \"Tesla wrote a number of books and articles for magazines and journals. Among his books are \"\n",
        "                     \"My Inventions: The Autobiography of Nikola Tesla, compiled and edited by Ben Johnston \"\n",
        "                     \"in 1983 from a series of 1919 magazine articles by Tesla which were republished in 1977. \"\n",
        "                     \"Tesla's legacy has endured in books, films, radio, TV, music, live theater, comics, and \"\n",
        "                     \"video games. The impact of the technologies invented or envisioned by Tesla is a recurring \"\n",
        "                     \"theme in several types of science fiction. \",\n",
        "                     \"qas\": [\n",
        "                         {\"question\": \"When did Tesla becοme a vegetarian?\",\n",
        "                          \"id\": \"Q1\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                         {\"question\": \"When did Tesla move to United States ?\",\n",
        "                          \"id\": \"Q2\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                         {\"question\": \"What year did Tesla die?\",\n",
        "                          \"id\": \"Q3\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                         {\"question\": \"Who edited the book My Inventions: The Autobiography of Nikola Tesla?\",\n",
        "                          \"id\": \"Q4\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                         {\"question\": \"In what age did Tesla died?\",\n",
        "                          \"id\": \"Q5\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                         {\"question\": \"Who developed an induction motor?\",\n",
        "                          \"id\": \"Q6\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                         {\"question\": \"Where Tesla was born?\",\n",
        "                          \"id\": \"Q7\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                         {\"question\": \"What did Tesla study?\",\n",
        "                          \"id\": \"Q8\",\n",
        "                          \"answers\": \"\",\n",
        "                          \"is_impossible\": \"False\",\n",
        "                          },\n",
        "                     ]}]}]}\n",
        "\n",
        "model.eval()\n",
        "test_samples = createSquadExamples(data)\n",
        "x_test, _ = createInputsTargets(test_samples)\n",
        "pred_start, pred_end = model(torch.tensor(x_test[0], dtype=torch.int64, device=device),\n",
        "                             torch.tensor(\n",
        "                                 x_test[1], dtype=torch.float, device=device),\n",
        "                             torch.tensor(x_test[2], dtype=torch.int64, device=device), return_dict=False)\n",
        "pred_start, pred_end = pred_start.detach().cpu(\n",
        ").numpy(), pred_end.detach().cpu().numpy()\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "    test_sample = test_samples[idx]\n",
        "    offsets = test_sample.offSets\n",
        "    start = np.argmax(start)\n",
        "    end = np.argmax(end)\n",
        "    pred_ans = None\n",
        "    if start >= len(offsets):\n",
        "        continue\n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "        pred_ans = test_sample.context[pred_char_start:]\n",
        "    print(\"Q: \" + test_sample.question)\n",
        "    print(\"A: \" + pred_ans)\n",
        "    print(\"----------------------------------------\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
